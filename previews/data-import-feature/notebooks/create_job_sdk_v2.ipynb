{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This is a Notebook created with Insturctions for Import data feature. \n",
        "\n",
        "It is important to follow the Pre-steps listed below carefully to ensure the proper working, else you might face issues and might have to do backtracking.\n",
        "You can give an appropriate names to your resources by updating the name in the corresponding YAML files in the samples or by creating your own YAML using the sample and referencing it in the following when you are ready to create. These are just samples provided for you to get familiar with the required parameters that needs to be passed to create a new resource.\n",
        "\n",
        "\n",
        "**1. Create test workspace with a compute instance 'cpu-instance'**\n",
        "\n",
        "If you don't have an Azure subscription, sign up to try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/) today.\n",
        "and follow the instructions to create a [AzureML workspace and compute instance](https://learn.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**2. Install SDKv2 private preview release**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install azure-ai-ml==0.0.71493720 --extra-index-url https://azuremlsdktestpypi.azureedge.net/azureml-v2-cli-e2e-test/71493720/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.identity import ManagedIdentityCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "subscription_id = '<your subscription here>'\n",
        "resource_group = '<your rg here>'\n",
        "workspace = '<your ws here>'\n",
        "ml_client = MLClient(ManagedIdentityCredential(), subscription_id, resource_group, workspace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Check for existing Connections**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ml_client.connections.get(name=<connection_name>)\n",
        "\n",
        "connection_list = ml_client.connections.list()\n",
        "\n",
        "for conn in connection_list:\n",
        "    print(conn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**OR create a new connection by the follwing instructions in [create_ws_connections.ipynb](./create_ws_connection_sdk_v2.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Job With Az SQL as an example using DatabaseImportSource class option**\n",
        "\n",
        "*NOTE:* The same can be used for other types such as Snowflake, Synapse and Az SQL jst by pointing to the right type, connection and query\n",
        "The `path` here is an example path and `{name}` ensures that the path is unique by substituting it with the name of the `job`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import FileImportSource,DatabaseImportSource, ImportJob\n",
        "from azure.ai.ml import import_job\n",
        "from azure.ai.ml import Output\n",
        "from azure.ai.ml import load_job\n",
        "\n",
        "data_output = Output(type='mltable', path='azureml://datastores/workspaceblobstore/paths/azureml/{name}/output_dir/azsql')\n",
        "data_source = DatabaseImportSource(type='azuresqldb', connection='azureml:<your_connection_name>', query='<your query here>')\n",
        "\n",
        "data_import_job = ImportJob(source=data_source, output=data_output)\n",
        "returned_job = ml_client.jobs.create_or_update(data_import_job)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Job With Snowflake as an example using DatabaseImportSource class option**\n",
        "\n",
        "*NOTE:* The same can be used for other types such as Snowflake, Synapse and Az SQL jst by pointing to the right type, connection and query\n",
        "The `path` here is an example path and `{name}` ensures that the path is unique by substituting it with the name of the `job`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import FileImportSource,DatabaseImportSource, ImportJob\n",
        "from azure.ai.ml import import_job\n",
        "from azure.ai.ml import Output\n",
        "from azure.ai.ml import load_job\n",
        "\n",
        "data_output = Output(type='mltable', path='azureml://datastores/workspaceblobstore/paths/azureml/{name}/output_dir/snowflake')\n",
        "data_source = DatabaseImportSource(type='snowflake', connection='azureml:my_snowflake_connection', query='select * from TPCH_SF1000.PARTSUPP')\n",
        "\n",
        "data_import_job = ImportJob(source=data_source, output=data_output)\n",
        "returned_job = ml_client.jobs.create_or_update(data_import_job)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Job With S3 as an example using FileImportSource class option**\n",
        "\n",
        "*NOTE:* The `path` here is an example path and `{name}` ensures that the path is unique by substituting it with the name of the `job`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import FileImportSource,DatabaseImportSource, ImportJob\n",
        "from azure.ai.ml import import_job\n",
        "from azure.ai.ml import Output\n",
        "from azure.ai.ml import load_job\n",
        "\n",
        "data_output = Output(type='uri_folder', path='azureml://datastores/workspaceblobstore/paths/azureml/{name}/output_dir/')\n",
        "data_source = FileImportSource(type='s3', connection='azureml:my_s3_connection', path='test1/*')\n",
        "\n",
        "data_import_job = ImportJob(source=data_source, output=data_output)\n",
        "returned_job = ml_client.jobs.create_or_update(data_import_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Job With Snowflake as an example with loading the YAML option**\n",
        "\n",
        "*NOTE:* The same can be used for other types such as S3. Az Synapse and Az SQL jst by pointing to the right YAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_import_job = load_job(path=\"./job/import_job_test_snowflake.yml\")\n",
        "returned_job: ImportJob = ml_client.jobs.create_or_update(job=data_import_job)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK V2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
